on: push
jobs:
  ollama:
    runs-on: ubuntu-24.04
    steps:
      - name: Run shell commands
        run: |
          free -h
          df -h
          lscpu
      - name: Run model
        uses: ai-action/ollama-action@v1
        id: model
        with:
          model: qwen2.5-coder:14b
          prompt: |
            Your primary task is to **migrate** user customizations from an `original values.yaml` file to a `new default values.yaml` file for a Helm chart. The key challenge is that the YAML structure of the `values.yaml` may have changed significantly between the chart versions. You must **refactor** the original customizations to fit the new structure.

            **Core Principles:**
            
            1.  **Preserve User Intent:** The values customized by the user in the original file must be carried over.
            2.  **Adopt New Structure:** The output must conform to the YAML key structure of the `new default values.yaml`.
            3.  **Minimal Output:** The final output should only contain the refactored/migrated customizations and their necessary parent keys from the new structure. Do **not** include any sections or default values from the `new default values.yaml` that were not customized in the `original values.yaml` or are not strictly required as parent keys for your customizations.
            
            **Instructions:**
            
            1.  **Identify Customizations:**
                *   Carefully examine the `original values.yaml`. Any key-value pair present is considered a user customization.
                *   Pay attention to entire blocks (like `ingress`, `resources`, `image`) and individual settings.
            
            2.  **Analyze New Structure:**
                *   Thoroughly parse the `new default values.yaml` to understand its hierarchical organization.
            
            3.  **Map and Refactor Customizations:**
                *   For each customization from the `original values.yaml`:
                    *   **Direct Match:** If a key path (e.g., `foo.bar.baz`) exists and is largely the same in both, place the user's custom value at that path in the new structure.
                    *   **Structural Relocation:** If a section or key has moved (e.g., what was `config.database` might now be `application.settings.database` or `dataSources.primary`), identify the new logical location and place the user's customization there. You may need to infer this based on semantic similarity of parent keys.
                    *   **Key Renaming:** If a key's name has changed but its purpose is the same (e.g., `enableFeatureX` becomes `featureXToggled`), map the value to the new key name in its correct location.
                    *   **Format Changes:** If the format of a value has changed (e.g., a boolean `true` becomes a string `"enabled"`, or a simple list `items: [a, b]` becomes a list of objects `items: [{name: a}, {name: b}]`), adapt the user's custom value to the new format while preserving the intent. For list-to-object transformations, infer sensible key names for the new objects if not obvious.
                    *   **Merging Sub-keys:** If the `original values.yaml` customizes a sub-key (e.g., `image.tag`) and the `new default values.yaml` provides other default sub-keys under the same parent (e.g., `image.repository`, `image.pullPolicy`), the output should include the user's customized sub-key *and* the new defaults for the other sub-keys under that parent, unless those were also explicitly customized in the original.
                        *   *Example:* If original has `image: {tag: "my-tag"}` and new default has `image: {repository: "new-repo", pullPolicy: "IfNotPresent", tag: ""}`, the output should be `image: {repository: "new-repo", pullPolicy: "IfNotPresent", tag: "my-tag"}`.
            
            4.  **Removed Settings:** If a setting from the `original values.yaml` has no clear equivalent in the `new default values.yaml`, it should be omitted from the output. You should note this in your explanation.
            
            5.  **Output:**
                *   Provide the updated `values.yaml` containing only the migrated customizations within the new structure.
                *   Provide a concise "Explanation of Changes" detailing:
                    *   How major blocks/customizations were mapped or refactored.
                    *   Any significant structural changes you addressed.
                    *   Any original customizations that were dropped because no equivalent was found.
            
            **Input Files:**
            
            **1. `original values.yaml` (User's current customized file):**
            ```yaml
            # Default helm values for n8n.
            # Default values within the n8n application can be found under https://github.com/n8n-io/n8n/blob/master/packages/cli/config/index.ts
            defaults:
            
            config:
              database:
                type: postgresdb
                postgresdb:
                  host: n8n-stolon-proxy
                  user: stolon
              generic:
                timezone: Europe/Brussels
            
            ## ALL possible n8n Values
            
            #
            #database:
            #  type:             # Type of database to use - Other possible types ['sqlite', 'mariadb', 'mysqldb', 'postgresdb'] - default: sqlite
            #  tablePrefix:      # Prefix for table names - default: ''
            #  postgresdb:
            #    database:       # PostgresDB Database - default: n8n
            #    host:           # PostgresDB Host - default: localhost
            #    password:        # PostgresDB Password - default: ''
            #    port:            # PostgresDB Port - default: 5432
            #    user:            # PostgresDB User - default: root
            #    schema:            # PostgresDB Schema - default: public
            #    ssl:
            #      ca:            # SSL certificate authority - default: ''
            #      cert:            # SSL certificate - default: ''
            #      key:            # SSL key - default: ''
            #      rejectUnauthorized:    # If unauthorized SSL connections should be rejected - default: true
            #  mysqldb:
            #    database:        # MySQL Database - default: n8n
            #    host:            # MySQL Host - default: localhost
            #    password:        # MySQL Password - default: ''
            #    port:            # MySQL Port - default: 3306
            #    user:            # MySQL User - default: root
            #credentials:
            #  overwrite:
            #    data:        # Overwrites for credentials - default: "{}"
            #    endpoint:    # Fetch credentials from API - default: ''
            #
            #executions:
            #  process:                # In what process workflows should be executed - possible values [main, own] - default: own
            #  timeout:                # Max run time (seconds) before stopping the workflow execution - default: -1
            #  maxTimeout:            # Max execution time (seconds) that can be set for a workflow individually - default: 3600
            #  saveDataOnError:        # What workflow execution data to save on error - possible values [all , none] - default: all
            #  saveDataOnSuccess:    # What workflow execution data to save on success - possible values [all , none] - default: all
            #  saveDataManualExecutions:    # Save data of executions when started manually via editor - default: false
            #  pruneData:            # Delete data of past executions on a rolling basis - default: false
            #  pruneDataMaxAge:        # How old (hours) the execution data has to be to get deleted - default: 336
            #  pruneDataTimeout:        # Timeout (seconds) after execution data has been pruned - default: 3600
            #generic:
            #  timezone:     # The timezone to use - default: America/New_York
            #path:         # Path n8n is deployed to - default: "/"
            #host:         # Host name n8n can be reached - default: localhost
            #port:         # HTTP port n8n can be reached - default: 5678
            #listen_address: # IP address n8n should listen on - default: 0.0.0.0
            #protocol:       # HTTP Protocol via which n8n can be reached - possible values [http , https] - default: http
            #ssl_key:        # SSL Key for HTTPS Protocol - default: ''
            #ssl_cert:       # SSL Cert for HTTPS Protocol - default: ''
            #security:
            #  excludeEndpoints: # Additional endpoints to exclude auth checks. Multiple endpoints can be separated by colon - default: ''
            #  basicAuth:
            #    active:     # If basic auth should be activated for editor and REST-API - default: false
            #    user:       # The name of the basic auth user - default: ''
            #    password:   # The password of the basic auth user - default: ''
            #    hash:       # If password for basic auth is hashed - default: false
            #  jwtAuth:
            #    active:               # If JWT auth should be activated for editor and REST-API - default: false
            #    jwtHeader:            # The request header containing a signed JWT - default: ''
            #    jwtHeaderValuePrefix: # The request header value prefix to strip (optional) default: ''
            #    jwksUri:              # The URI to fetch JWK Set for JWT authentication - default: ''
            #    jwtIssuer:            # JWT issuer to expect (optional) - default: ''
            #    jwtNamespace:         # JWT namespace to expect (optional) -  default: ''
            #    jwtAllowedTenantKey:  # JWT tenant key name to inspect within JWT namespace (optional) - default: ''
            #    jwtAllowedTenant:     # JWT tenant to allow (optional) - default: ''
            #endpoints:
            #  rest:       # Path for rest endpoint  default: rest
            #  webhook:    # Path for webhook endpoint  default: webhook
            #  webhookTest: # Path for test-webhook endpoint  default: webhook-test
            #externalHookFiles: # Files containing external hooks. Multiple files can be separated by colon - default: ''
            #nodes:
            #  exclude: # Nodes not to load - default: "[]"
            #  errorTriggerType: # Node Type to use as Error Trigger - default: n8n-nodes-base.errorTrigger
            
            # Set additional environment variables on the Deployment
            extraEnv:
              WEBHOOK_TUNNEL_URL: "https://n8n.unixfox.eu/"
            
            image:
              pullPolicy: Always
              tag: "latest"
            
            ingress:
              enabled: true
              annotations:
                kubernetes.io/tls-acme: "true"
                cert-manager.io/cluster-issuer: buypass-prod
                kubernetes.io/ingress.class: nginx
                nginx.ingress.kubernetes.io/proxy-body-size: 100m
                nginx.ingress.kubernetes.io/auth-url: "https://oauth.unixfox.eu/oauth2/auth"
                nginx.ingress.kubernetes.io/auth-signin: "https://oauth.unixfox.eu/oauth2/start?rd=https://n8n.unixfox.eurequest_uri$is_args$args"
              hosts:
                - host: n8n.unixfox.eu
                  paths:
                    - "/"
            
              tls:
                - secretName: n8n-chart-tls
                  hosts:
                    - n8n.unixfox.eu
            
            nodeSelector:
              topology.kubernetes.io/zone: eu-amsterdam-1-AD-1
            ```
            
            2. new default values.yaml (Default values.yaml from the NEW chart version):
            ```
            # README
            # High level values structure, overview and explanation of the values.yaml file.
            # 1. Global and chart wide values, like the image repository, image tag, etc.
            # 2. Ingress, (default is nginx, but you can change it to your own ingress controller)
            # 3. Main n8n app configuration + kubernetes specific settings
            # 4. Worker related settings + kubernetes specific settings
            # 5. Webhook related settings + kubernetes specific settings
            # 6. Raw Resources to pass through your own manifests like GatewayAPI, ServiceMonitor etc.
            # 7. Valkey/Redis related settings and kubernetes specific settings
            
            #
            # Global common config for this entire n8n deployment
            #
            
            image:
              repository: n8nio/n8n
              pullPolicy: IfNotPresent
              # Overrides the image tag whose default is the chart appVersion.
              tag: ""
            imagePullSecrets: []
            
            # The Name to use for the chart. Will be the prefix of all resources aka. The Chart.Name (default is 'n8n')
            nameOverride:
            # Override the full name of the deployment. When empty, the name will be "{release-name}-{chart-name}" or the value of nameOverride if specified
            fullnameOverride:
            
            # Add entries to a pod's /etc/hosts file, mapping custom IP addresses to hostnames.
            hostAliases: []
              # - ip: 8.8.8.8
              #   hostnames:
              #     - service-example.local
            #
            # Ingress
            #
            ingress:
              enabled: false
              annotations: {}
              # define a custom ingress class Name, like "traefik" or "nginx"
              className: ""
              hosts:
                - host: workflow.example.com
                  paths: []
              tls:
                - hosts:
                    - workflow.example.com
                  secretName: host-domain-cert
            
            # the main (n8n) application related configuration + Kubernetes specific settings
            # The config: {} dictionary is converted to environmental variables in the ConfigMap.
            main:
              # See https://docs.n8n.io/hosting/configuration/environment-variables/ for all values.
              config: {}
              #    n8n:
              #    db:
              #      type: postgresdb
              #      postgresdb:
              #        host: 192.168.0.52
            
              # Dictionary for secrets, unlike config:, the values here will end up in the secret file.
              # The YAML entry db.postgresdb.password: my_secret is transformed DB_POSTGRESDB_password=bXlfc2VjcmV0
              # See https://docs.n8n.io/hosting/configuration/environment-variables/
              secret: {}
              #    n8n:
              #     if you run n8n stateless, you should provide an encryption key here.
              #      encryption_key:
              #
              #    db:
              #      postgresdb:
              #        password: 'big secret'
            
              # Extra environmental variables, so you can reference other configmaps and secrets into n8n as env vars.
              extraEnv:
              #    N8N_DB_POSTGRESDB_NAME:
              #      valueFrom:
              #        secretKeyRef:
              #          name: db-app
              #          key: dbname
              #
              # N8n Kubernetes specific settings
              #
              persistence:
                # If true, use a Persistent Volume Claim, If false, use emptyDir
                enabled: false
                # what type volume, possible options are [existing, emptyDir, dynamic] dynamic for Dynamic Volume Provisioning, existing for using an existing Claim
                type: emptyDir
                # Persistent Volume Storage Class
                # If defined, storageClassName: <storageClass>
                # If set to "-", storageClassName: "", which disables dynamic provisioning
                # If undefined (the default) or set to null, no storageClassName spec is
                #   set, choosing the default provisioner.  (gp2 on AWS, standard on
                #   GKE, AWS & OpenStack)
                #
                # storageClass: "-"
                # PVC annotations
                #
                # If you need this annotation include it under `values.yml` file and pvc.yml template will add it.
                # This is not maintained at Helm v3 anymore.
                # https://github.com/8gears/n8n-helm-chart/issues/8
                #
                # annotations:
                #   helm.sh/resource-policy: keep
                # Persistent Volume Access Mode
                #
                accessModes:
                  - ReadWriteOnce
                # Persistent Volume size
                size: 1Gi
                # Use an existing PVC
                # existingClaim:
            
              extraVolumes: []
              #    - name: db-ca-cert
              #      secret:
              #        secretName: db-ca
              #        items:
              #          - key: ca.crt
              #            path: ca.crt
            
              extraVolumeMounts: []
              #    - name: db-ca-cert
              #      mountPath: /etc/ssl/certs/postgresql
              #      readOnly: true
            
            
              # Number of desired pods. More than one pod is supported in n8n enterprise.
              replicaCount: 1
            
              # here you can specify the deployment strategy as Recreate or RollingUpdate with optional maxSurge and maxUnavailable
              # If these options are not set, default values are 25%
              # deploymentStrategy:
              #  type: Recreate | RollingUpdate
              #  maxSurge: "50%"
              #  maxUnavailable: "50%"
            
              deploymentStrategy:
                type: "Recreate"
                #  maxSurge: "50%"
                #  maxUnavailable: "50%"
            
              serviceAccount:
                # Specifies whether a service account should be created
                create: true
                # Annotations to add to the service account
                annotations: {}
                # The name of the service account to use.
                # If not set and create is true, a name is generated using the fullname template
                name: ""
            
              # Annotations to be implemented on the main service deployment
              deploymentAnnotations: {}
              # Labels to be implemented on the main service deployment
              deploymentLabels: {}
              # Annotations to be implemented on the main service pod
              podAnnotations: {}
              # Labels to be implemented on the main service pod
              podLabels: {}
            
              podSecurityContext:
                runAsNonRoot: true
                runAsUser: 1000
                runAsGroup: 1000
                fsGroup: 1000
            
              securityContext: {}
              # capabilities:
              #   drop:
              #   - ALL
              # readOnlyRootFilesystem: true
              #  runAsNonRoot: true
              #  runAsUser: 1000
            
              # here you can specify lifecycle hooks - it can be used e.g., to easily add packages to the container without building
              # your own docker image
              # see https://github.com/8gears/n8n-helm-chart/pull/30
              lifecycle: {}
            
              #  here's the sample configuration to add mysql-client to the container
              # lifecycle:
              #  postStart:
              #    exec:
              #      command: ["/bin/sh", "-c", "apk add mysql-client"]
            
              # here you can override a command for main container
              # it may be used to override a starting script (e.g., to resolve issues like https://github.com/n8n-io/n8n/issues/6412) or run additional preparation steps (e.g., installing additional software)
              command: []
            
              # sample configuration that overrides starting script and solves above issue (also it runs n8n as root, so be careful):
              # command:
              #  - tini
              #  - --
              #  - /bin/sh
              #  - -c
              #  - chmod o+rx /root; chown -R node /root/.n8n || true; chown -R node /root/.n8n; ln -s /root/.n8n /home/node; chown -R node /home/node || true; node /usr/local/bin/n8n
            
              # here you can override the livenessProbe for the main container
              # it may be used to increase the timeout for the livenessProbe (e.g., to resolve issues like
            
              livenessProbe:
                httpGet:
                  path: /healthz
                  port: http
                # initialDelaySeconds: 30
                # periodSeconds: 10
                # timeoutSeconds: 5
                # failureThreshold: 6
                # successThreshold: 1
            
              # here you can override the readinessProbe for the main container
              # it may be used to increase the timeout for the readinessProbe (e.g., to resolve issues like
            
              readinessProbe:
                httpGet:
                  path: /healthz
                  port: http
                # initialDelaySeconds: 30
                # periodSeconds: 10
                # timeoutSeconds: 5
                # failureThreshold: 6
                # successThreshold: 1
            
              # List of initialization containers belonging to the pod. Init containers are executed in order prior to containers being started.
              # See https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
              initContainers: []
              #    - name: init-data-dir
              #      image: "{{ .Values.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}"
              #      command: [ "/bin/sh", "-c", "mkdir -p /home/node/.n8n/" ]
              #      volumeMounts:
              #        - name: data
              #          mountPath: /home/node/.n8n
            
            
              service:
                enabled: true
                annotations: {}
                # -- Service types allow you to specify what kind of Service you want.
                # E.g., ClusterIP, NodePort, LoadBalancer, ExternalName
                type: ClusterIP
                # -- Service port
                port: 80
            
              resources: {}
              # We usually recommend not specifying default resources and to leave this as a conscious
              # choice for the user. This also increases chances charts run on environments with little
              # resources, such as Minikube. If you do want to specify resources, uncomment the following
              # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
              # limits:
              #   cpu: 100m
              #   memory: 128Mi
              # requests:
              #   cpu: 100m
              #   memory: 128Mi
            
              autoscaling:
                enabled: false
                minReplicas: 1
                maxReplicas: 100
                targetCPUUtilizationPercentage: 80
                # targetMemoryUtilizationPercentage: 80
            
              nodeSelector: {}
              tolerations: []
              affinity: {}
            
            # # # # # # # # # # # # # # # #
            #
            # Worker related settings
            #
            worker:
              enabled: false
            
              # additional (to main) config for worker
              config: {}
            
              # additional (to main) config for worker
              secret: {}
            
              # Extra environmental variables, so you can reference other configmaps and secrets into n8n as env vars.
              extraEnv: {}
            
              # Define the number of jobs a worker can run in parallel by using the concurrency flag. Default is 10
              concurrency: 10
            
              #
              # Worker Kubernetes specific settings
              #
              persistence:
                # If true, use a Persistent Volume Claim, If false, use emptyDir
                enabled: false
                # what type volume, possible options are [existing, emptyDir, dynamic] dynamic for Dynamic Volume Provisioning, existing for using an existing Claim
                type: emptyDir
                # Persistent Volume Storage Class
                # If defined, storageClassName: <storageClass>
                # If set to "-", storageClassName: "", which disables dynamic provisioning
                # If undefined (the default) or set to null, no storageClassName spec is
                #   set, choosing the default provisioner.  (gp2 on AWS, standard on
                #   GKE, AWS & OpenStack)
                #
                # storageClass: "-"
                # PVC annotations
                #
                # If you need this annotation include it under `values.yml` file and pvc.yml template will add it.
                # This is not maintained at Helm v3 anymore.
                # https://github.com/8gears/n8n-helm-chart/issues/8
                #
                # annotations:
                #   helm.sh/resource-policy: keep
                # Persistent Volume Access Mode
                accessModes:
                  - ReadWriteOnce
                # Persistent Volume size
                size: 1Gi
                # Use an existing PVC
                # existingClaim:
            
              # Number of desired pods.
              replicaCount: 1
            
              # here you can specify the deployment strategy as Recreate or RollingUpdate with optional maxSurge and maxUnavailable
              # If these options are not set, default values are 25%
              # deploymentStrategy:
              #  type: RollingUpdate
              #  maxSurge: "50%"
              #  maxUnavailable: "50%"
            
              deploymentStrategy:
                type: "Recreate"
                # maxSurge: "50%"
                # maxUnavailable: "50%"
            
              serviceAccount:
                # Specifies whether a service account should be created
                create: true
                # Annotations to add to the service account
                annotations: {}
                # The name of the service account to use.
                # If not set and create is true, a name is generated using the fullname template
                name: ""
            
              # Annotations to be implemented on the worker deployment
              deploymentAnnotations: {}
              # Labels to be implemented on the worker deployment
              deploymentLabels: {}
              # Annotations to be implemented on the worker pod
              podAnnotations: {}
              # Labels to be implemented on the worker pod
              podLabels: {}
            
              podSecurityContext:
                runAsNonRoot: true
                runAsUser: 1000
                runAsGroup: 1000
                fsGroup: 1000
            
              securityContext: {}
              # capabilities:
              #   drop:
              #   - ALL
              # readOnlyRootFilesystem: true
              #  runAsNonRoot: true
              #  runAsUser: 1000
            
              # here you can specify lifecycle hooks - it can be used e.g., to easily add packages to the container without building
              # your own docker image
              # see https://github.com/8gears/n8n-helm-chart/pull/30
              lifecycle: {}
            
              #  here's the sample configuration to add mysql-client to the container
              # lifecycle:
              #  postStart:
              #    exec:
              #      command: ["/bin/sh", "-c", "apk add mysql-client"]
            
              # here you can override a command for worker container
              # it may be used to override a starting script (e.g., to resolve issues like https://github.com/n8n-io/n8n/issues/6412) or
              # run additional preparation steps (e.g., installing additional software)
              command: []
            
              # sample configuration that overrides starting script and solves above issue (also it runs n8n as root, so be careful):
              # command:
              #  - tini
              #  - --
              #  - /bin/sh
              #  - -c
              #  - chmod o+rx /root; chown -R node /root/.n8n || true; chown -R node /root/.n8n; ln -s /root/.n8n /home/node; chown -R node /home/node || true; node /usr/local/bin/n8n
            
              # command args
              commandArgs: []
            
              # here you can override the livenessProbe for the main container
              # it may be used to increase the timeout for the livenessProbe (e.g., to resolve issues like
              livenessProbe:
                httpGet:
                  path: /healthz
                  port: http
                # initialDelaySeconds: 30
                # periodSeconds: 10
                # timeoutSeconds: 5
                # failureThreshold: 6
                # successThreshold: 1
            
              # here you can override the readinessProbe for the main container
              # it may be used to increase the timeout for the readinessProbe (e.g., to resolve issues like
            
              readinessProbe:
                httpGet:
                  path: /healthz
                  port: http
                # initialDelaySeconds: 30
                # periodSeconds: 10
                # timeoutSeconds: 5
                # failureThreshold: 6
                # successThreshold: 1
            
              # List of initialization containers belonging to the pod. Init containers are executed in order prior to containers being started.
              # See https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
              initContainers: []
            
              service:
                annotations: {}
                # -- Service types allow you to specify what kind of Service you want.
                # E.g., ClusterIP, NodePort, LoadBalancer, ExternalName
                type: ClusterIP
                # -- Service port
                port: 80
            
              resources: {}
              # We usually recommend not specifying default resources and to leave this as a conscious
              # choice for the user. This also increases chances charts run on environments with little
              # resources, such as Minikube. If you do want to specify resources, uncomment the following
              # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
              # limits:
              #   cpu: 100m
              #   memory: 128Mi
              # requests:
              #   cpu: 100m
              #   memory: 128Mi
            
              autoscaling:
                enabled: false
                minReplicas: 1
                maxReplicas: 100
                targetCPUUtilizationPercentage: 80
                # targetMemoryUtilizationPercentage: 80
            
              nodeSelector: {}
              tolerations: []
              affinity: {}
            
            # Webhook related settings
            # With .Values.scaling.webhook.enabled=true you disable Webhooks from the main process, but you enable the processing on a different Webhook instance.
            # See https://github.com/8gears/n8n-helm-chart/issues/39#issuecomment-1579991754 for the full explanation.
            # Webhook processes rely on Valkey/Redis too.
            webhook:
              enabled: false
              # additional (to main) config for webhook
              config: {}
              # additional (to main) config for webhook
              secret: {}
            
              # Extra environmental variables, so you can reference other configmaps and secrets into n8n as env vars.
              extraEnv: {}
              #   WEBHOOK_URL:
              #   value: "http://webhook.domain.tld"
            
            
              #
              # Webhook Kubernetes specific settings
              #
              persistence:
                # If true, use a Persistent Volume Claim, If false, use emptyDir
                enabled: false
                # what type volume, possible options are [existing, emptyDir, dynamic] dynamic for Dynamic Volume Provisioning, existing for using an existing Claim
                type: emptyDir
                # Persistent Volume Storage Class
                # If defined, storageClassName: <storageClass>
                # If set to "-", storageClassName: "", which disables dynamic provisioning
                # If undefined (the default) or set to null, no storageClassName spec is
                #   set, choosing the default provisioner.  (gp2 on AWS, standard on
                #   GKE, AWS & OpenStack)
                #
                # storageClass: "-"
                # PVC annotations
                #
                # If you need this annotation include it under `values.yml` file and pvc.yml template will add it.
                # This is not maintained at Helm v3 anymore.
                # https://github.com/8gears/n8n-helm-chart/issues/8
                #
                # annotations:
                #   helm.sh/resource-policy: keep
                # Persistent Volume Access Mode
                #
                accessModes:
                  - ReadWriteOnce
                # Persistent Volume size
                #
                size: 1Gi
                # Use an existing PVC
                #
                # existingClaim:
            
              # Number of desired pods.
              replicaCount: 1
            
              # here you can specify the deployment strategy as Recreate or RollingUpdate with optional maxSurge and maxUnavailable
              # If these options are not set, default values are 25%
              # deploymentStrategy:
              #  type: RollingUpdate
              #  maxSurge: "50%"
              #  maxUnavailable: "50%"
            
              deploymentStrategy:
                type: "Recreate"
            
              nameOverride: ""
              fullnameOverride: ""
            
              serviceAccount:
                # Specifies whether a service account should be created
                create: true
                # Annotations to add to the service account
                annotations: {}
                # The name of the service account to use.
                # If not set and create is true, a name is generated using the fullname template
                name: ""
            
              # Annotations to be implemented on the webhook deployment
              deploymentAnnotations: {}
              # Labels to be implemented on the webhook deployment
              deploymentLabels: {}
              # Annotations to be implemented on the webhook pod
              podAnnotations: {}
              # Labels to be implemented on the webhook pod
              podLabels: {}
            
              podSecurityContext:
                runAsNonRoot: true
                runAsUser: 1000
                runAsGroup: 1000
                fsGroup: 1000
            
              securityContext: {}
              # capabilities:
              #   drop:
              #   - ALL
              # readOnlyRootFilesystem: true
              #  runAsNonRoot: true
              #  runAsUser: 1000
            
              # here you can specify lifecycle hooks - it can be used e.g., to easily add packages to the container without building
              # your own docker image
              # see https://github.com/8gears/n8n-helm-chart/pull/30
              lifecycle: {}
            
              #  here's the sample configuration to add mysql-client to the container
              # lifecycle:
              #  postStart:
              #    exec:
              #      command: ["/bin/sh", "-c", "apk add mysql-client"]
            
              # here you can override a command for main container
              # it may be used to override a starting script (e.g., to resolve issues like https://github.com/n8n-io/n8n/issues/6412) or
              # run additional preparation steps (e.g., installing additional software)
              command: []
            
              # sample configuration that overrides starting script and solves above issue (also it runs n8n as root, so be careful):
              # command:
              #  - tini
              #  - --
              #  - /bin/sh
              #  - -c
              #  - chmod o+rx /root; chown -R node /root/.n8n || true; chown -R node /root/.n8n; ln -s /root/.n8n /home/node; chown -R node /home/node || true; node /usr/local/bin/n8n
              # Command Arguments
              commandArgs: []
            
              # here you can override the livenessProbe for the main container
              # it may be used to increase the timeout for the livenessProbe (e.g., to resolve issues like
            
              livenessProbe:
                httpGet:
                  path: /healthz
                  port: http
                # initialDelaySeconds: 30
                # periodSeconds: 10
                # timeoutSeconds: 5
                # failureThreshold: 6
                # successThreshold: 1
            
              # here you can override the readinessProbe for the main container
              # it may be used to increase the timeout for the readinessProbe (e.g., to resolve issues like
            
              readinessProbe:
                httpGet:
                  path: /healthz
                  port: http
                # initialDelaySeconds: 30
                # periodSeconds: 10
                # timeoutSeconds: 5
                # failureThreshold: 6
                # successThreshold: 1
            
              # List of initialization containers belonging to the pod. Init containers are executed in order prior to containers being started.
              # See https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
              initContainers: []
            
              service:
                annotations: {}
                # -- Service types allow you to specify what kind of Service you want.
                # E.g., ClusterIP, NodePort, LoadBalancer, ExternalName
                type: ClusterIP
                # -- Service port
                port: 80
            
              resources: {}
              # We usually recommend not specifying default resources and to leave this as a conscious
              # choice for the user. This also increases chances charts run on environments with little
              # resources, such as Minikube. If you do want to specify resources, uncomment the following
              # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
              # limits:
              #   cpu: 100m
              #   memory: 128Mi
              # requests:
              #   cpu: 100m
              #   memory: 128Mi
              autoscaling:
                enabled: false
                minReplicas: 1
                maxReplicas: 100
                targetCPUUtilizationPercentage: 80
                # targetMemoryUtilizationPercentage: 80
              nodeSelector: {}
              tolerations: []
              affinity: {}
            
            #
            # User defined supplementary K8s manifests
            #
            
            #  Takes a list of Kubernetes manifests and merges each resource with a default metadata.labels map and
            #  installs the result.
            #  Use this to add any arbitrary Kubernetes manifests alongside this chart instead of kubectl and scripts.
            extraManifests: []
            #  - apiVersion: v1
            #    kind: ConfigMap
            #    metadata:
            #      name: example-config
            #    data:
            #      example.property.1: "value1"
            #      example.property.2: "value2"
            # As an alternative to the above, you can also use a string as the value of the data field.
            #  - |
            #    apiVersion: v1
            #    kind: ConfigMap
            #    metadata:
            #      name: example-config-string
            #    data:
            #      example.property.1: "value1"
            #      example.property.2: "value2"
            
            # String extraManifests supports using variables directly within a string manifest.
            # Templates are rendered using the context defined in the values.yaml file, enabling dynamic and flexible content customization.
            extraTemplateManifests: []
            #  - |
            #    apiVersion: v1
            #    kind: ConfigMap
            #    metadata:
            #      name: my-config
            #    stringData:
            #      image_name: {{ .Values.image.repository }}
            
            # Bitnami Valkey configuration
            # https://artifacthub.io/packages/helm/bitnami/valkey
            valkey:
              enabled: false
              # architecture: standalone
              #
              # primary:
              #   persistence:
              #     enabled: false
              #     existingClaim: ""
              #     size: 2Gi
            ```

      - name: Run shell commands
        run: |
          free -h
          df -h
      - name: Print response
        run: echo "$response"
        env:
          response: ${{ steps.model.outputs.response }}
